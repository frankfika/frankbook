---
section_id: "2.3.1"
title: "scripts/：脚本文件的组织与调用"
status: draft
word_count: 2720
target_words: 2500
---

# 2.3.1 scripts/：脚本文件的组织与调用

## 为什么要使用scripts目录

在前面的章节中，我们讨论了确定性与创造性分离原则——将确定性任务交给脚本，创造性任务交给AI。这一节的焦点是：如何有效地组织和调用这些脚本。

想象一下没有良好组织的脚本目录：
- 所有脚本堆在一个目录里，难以找到需要的
- 脚本命名混乱，不知道哪个是做什么的
- 脚本之间互相依赖，却不知道依赖关系
- 相同功能的脚本在不同Skill中重复编写

良好的脚本组织不仅是代码管理的问题，更是Skill可维护性和可复用性的基础。

## scripts目录的结构设计

### 基本结构

一个典型的scripts目录结构：

```
scripts/
├── analyze/              # 分析类脚本
│   ├── complexity.py     # 复杂度分析
│   ├── dependencies.py   # 依赖分析
│   └── security.py       # 安全扫描
├── generate/             # 生成类脚本
│   ├── report.py         # 报告生成
│   └── template.py       # 模板处理
├── utils/                # 工具类脚本
│   ├── file_ops.py       # 文件操作
│   ├── git_helper.py     # Git操作
│   └── validator.py      # 验证工具
└── __init__.py           # 包初始化（可选）
```

### 按功能分层

根据脚本的职责，可以分为几个层次：

**1. 核心分析层（analyze/）**

处理确定性分析任务：

```python
# scripts/analyze/complexity.py
#!/usr/bin/env python3
"""计算代码圈复杂度"""
import ast
import sys

def calculate_complexity(file_path):
    with open(file_path, 'r') as f:
        tree = ast.parse(f.read())

    complexities = []
    for node in ast.walk(tree):
        if isinstance(node, (ast.FunctionDef, ast.ClassDef)):
            # 计算圈复杂度的逻辑
            complexity = 1
            for child in ast.walk(node):
                if isinstance(child, (ast.If, ast.While, ast.For,
                                     ast.ExceptHandler, ast.With)):
                    complexity += 1
            complexities.append({
                'name': node.name,
                'complexity': complexity,
                'line': node.lineno
            })

    return complexities

if __name__ == '__main__':
    import json
    result = calculate_complexity(sys.argv[1])
    print(json.dumps(result, indent=2))
```

**2. 内容生成层（generate/）**

处理报告和文档的格式化：

```python
# scripts/generate/report.py
#!/usr/bin/env python3
"""生成标准化报告"""
import json
import sys
from datetime import datetime

def generate_markdown_report(data, template='standard'):
    """基于模板生成Markdown报告"""
    report = []
    report.append(f"# 分析报告\n")
    report.append(f"生成时间：{datetime.now().isoformat()}\n")
    report.append(f"## 概述\n")
    report.append(f"- 分析文件：{data.get('file_count', 0)}\n")
    report.append(f"- 发现问题：{data.get('issue_count', 0)}\n")
    report.append(f"\n## 详细发现\n")

    for issue in data.get('issues', []):
        report.append(f"### {issue['title']}\n")
        report.append(f"- 位置：{issue['location']}\n")
        report.append(f"- 严重程度：{issue['severity']}\n")
        report.append(f"- 描述：{issue['description']}\n\n")

    return '\n'.join(report)

if __name__ == '__main__':
    with open(sys.argv[1]) as f:
        data = json.load(f)
    print(generate_markdown_report(data))
```

**3. 工具函数层（utils/）**

提供通用功能支持：

```python
# scripts/utils/file_ops.py
#!/usr/bin/env python3
"""文件操作工具"""
import os
import hashlib

def get_file_info(file_path):
    """获取文件元信息"""
    stat = os.stat(file_path)
    return {
        'path': file_path,
        'size': stat.st_size,
        'modified': stat.st_mtime,
        'hash': calculate_hash(file_path)
    }

def calculate_hash(file_path, algorithm='md5'):
    """计算文件哈希值"""
    hasher = hashlib.new(algorithm)
    with open(file_path, 'rb') as f:
        for chunk in iter(lambda: f.read(4096), b''):
            hasher.update(chunk)
    return hasher.hexdigest()

def find_files(directory, pattern='*', exclude=None):
    """递归查找文件"""
    import fnmatch
    matches = []
    for root, dirnames, filenames in os.walk(directory):
        # 应用排除规则
        if exclude:
            dirnames[:] = [d for d in dirnames
                          if not any(fnmatch.fnmatch(d, e) for e in exclude)]

        for filename in fnmatch.filter(filenames, pattern):
            matches.append(os.path.join(root, filename))
    return matches
```

## 脚本调用机制

### 从SKILL.md调用脚本

**1. 直接执行**

```markdown
## 执行步骤

1. **分析复杂度**
   ```bash
   python scripts/analyze/complexity.py {{file_path}}
   ```

2. **生成报告**
   ```bash
   python scripts/generate/report.py /tmp/analysis_result.json
   ```
```

**2. 传递参数**

```markdown
## 执行步骤

1. **运行多维度分析**
   ```bash
   python scripts/analyze/full_scan.py \
     --target={{project_path}} \
     --output=/tmp/result.json \
     --exclude=node_modules,venv \
     --format=json
   ```
```

**3. 管道组合**

```markdown
## 执行步骤

1. **分析并格式化**
   ```bash
   python scripts/analyze/complexity.py {{file_path}} | \
   python scripts/generate/report.py --format=markdown
   ```
```

### 脚本间的协作

**1. 数据传递（JSON格式）**

```python
# scripts/analyze/dependencies.py
import json
import sys

def analyze_dependencies(file_path):
    # 分析逻辑...
    result = {
        'file': file_path,
        'imports': ['os', 'sys', 'json'],
        'external_deps': ['requests', 'numpy'],
        'circular_deps': []
    }
    return result

if __name__ == '__main__':
    result = analyze_dependencies(sys.argv[1])
    print(json.dumps(result))  # 输出JSON供其他脚本消费
```

```python
# scripts/generate/dep_graph.py
import json
import sys

def generate_graph(data):
    """基于依赖数据生成可视化图"""
    # 读取stdin或文件
    if len(sys.argv) > 1:
        with open(sys.argv[1]) as f:
            data = json.load(f)
    else:
        data = json.load(sys.stdin)

    # 生成Mermaid图
    lines = ['graph TD']
    for dep in data.get('external_deps', []):
        lines.append(f"    A[{data['file']}] --> B[{dep}]")

    return '\n'.join(lines)

if __name__ == '__main__':
    print(generate_graph(None))
```

**2. 使用共享库**

```python
# scripts/utils/common.py
"""共享工具函数"""
import logging
import sys

def setup_logging(level=logging.INFO):
    """配置标准日志格式"""
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        stream=sys.stderr
    )
    return logging.getLogger(__name__)

def handle_error(message, exit_code=1):
    """统一错误处理"""
    print(f"Error: {message}", file=sys.stderr)
    sys.exit(exit_code)

def validate_file_exists(path):
    """验证文件存在"""
    import os
    if not os.path.exists(path):
        handle_error(f"File not found: {path}")
    return path
```

```python
# scripts/analyze/complexity.py
from utils.common import setup_logging, validate_file_exists

logger = setup_logging()

def main():
    file_path = validate_file_exists(sys.argv[1])
    logger.info(f"Analyzing {file_path}")
    # ... 分析逻辑

if __name__ == '__main__':
    main()
```

## 脚本命名规范

### 命名原则

**1. 动词+名词结构**

```
✓ analyze_complexity.py
✓ generate_report.py
✓ validate_config.py
✓ extract_functions.py
✗ complexity.py          # 太笼统
✗ report.py              # 不知道是生成还是解析
✗ config.py              # 不知道是验证还是读取
```

**2. 使用下划线分隔**

```
✓ analyze_dependencies.py
✗ analyzeDependencies.py    # Python不推荐使用驼峰
✗ analyze-dependencies.py   # 部分系统不支持连字符
```

**3. 包含版本号（必要时）**

```
scripts/
├── analyze_complexity.py      # 当前版本
├── analyze_complexity_v2.py   # 新版本（重大变更）
└── analyze_complexity_legacy.py # 旧版本（兼容支持）
```

### 目录与文件的关系

```
scripts/
├── analyze/                    # 目录：分析类脚本
│   ├── __init__.py            # 空文件，使目录成为Python包
│   ├── complexity.py          # 复杂度分析
│   ├── dependencies.py        # 依赖分析
│   └── security.py            # 安全分析
├── generate/                   # 目录：生成类脚本
│   ├── report.py              # 报告生成
│   └── template.py            # 模板处理
└── utils/                      # 目录：工具脚本
    ├── file_ops.py            # 文件操作
    └── validators.py          # 验证工具
```

## 错误处理与日志

### 标准化错误处理

```python
# scripts/utils/errors.py
"""标准错误定义"""

class ScriptError(Exception):
    """脚本基础错误"""
    def __init__(self, message, exit_code=1):
        self.message = message
        self.exit_code = exit_code
        super().__init__(self.message)

class ValidationError(ScriptError):
    """验证错误"""
    def __init__(self, message):
        super().__init__(message, exit_code=2)

class FileNotFoundError(ScriptError):
    """文件不存在错误"""
    def __init__(self, path):
        super().__init__(f"File not found: {path}", exit_code=3)

class ParseError(ScriptError):
    """解析错误"""
    def __init__(self, message, line=None):
        msg = f"{message} at line {line}" if line else message
        super().__init__(msg, exit_code=4)
```

### 结构化日志输出

```python
# scripts/analyze/complexity.py
import json
import logging
import sys
from utils.errors import ScriptError, FileNotFoundError

logger = logging.getLogger(__name__)

def main():
    try:
        if len(sys.argv) < 2:
            raise ScriptError("Usage: complexity.py <file_path>")

        file_path = sys.argv[1]
        result = analyze(file_path)

        # 成功输出
        output = {
            'success': True,
            'data': result,
            'stats': {
                'functions_analyzed': len(result),
                'avg_complexity': sum(r['complexity'] for r in result) / len(result) if result else 0
            }
        }
        print(json.dumps(output, indent=2))
        return 0

    except FileNotFoundError as e:
        logger.error(f"File not found: {e}")
        output = {'success': False, 'error': 'file_not_found', 'message': str(e)}
        print(json.dumps(output), file=sys.stderr)
        return 3

    except ScriptError as e:
        logger.error(f"Script error: {e}")
        output = {'success': False, 'error': 'script_error', 'message': str(e)}
        print(json.dumps(output), file=sys.stderr)
        return e.exit_code

    except Exception as e:
        logger.exception("Unexpected error")
        output = {'success': False, 'error': 'unexpected', 'message': str(e)}
        print(json.dumps(output), file=sys.stderr)
        return 99

if __name__ == '__main__':
    sys.exit(main())
```

## 脚本的测试与验证

### 单元测试

```python
# tests/test_complexity.py
import unittest
import sys
import os

# 添加scripts目录到路径
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'scripts'))

from analyze.complexity import calculate_complexity
import tempfile

class TestComplexity(unittest.TestCase):
    def test_simple_function(self):
        code = '''
def simple():
    return 1
'''
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
            f.write(code)
            f.flush()
            result = calculate_complexity(f.name)

        self.assertEqual(len(result), 1)
        self.assertEqual(result[0]['complexity'], 1)
        os.unlink(f.name)

    def test_complex_function(self):
        code = '''
def complex_func(x):
    if x > 0:
        if x < 10:
            return x
        else:
            return 10
    return 0
'''
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
            f.write(code)
            f.flush()
            result = calculate_complexity(f.name)

        self.assertEqual(len(result), 1)
        self.assertEqual(result[0]['complexity'], 3)  # 1 + if + nested if
        os.unlink(f.name)

if __name__ == '__main__':
    unittest.main()
```

### 集成测试

```bash
#!/bin/bash
# tests/integration_test.sh

set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)/scripts"
TEST_DATA="$(dirname "$0")/test_data"

echo "=== Running Integration Tests ==="

# Test 1: Complexity analysis
echo "Test 1: Complexity analysis"
result=$(python "$SCRIPT_DIR/analyze/complexity.py" "$TEST_DATA/sample.py")
if echo "$result" | grep -q '"complexity":'; then
    echo "✓ PASS"
else
    echo "✗ FAIL"
    exit 1
fi

# Test 2: Report generation
echo "Test 2: Report generation"
echo '{"issues": [{"title": "Test", "severity": "high"}]}' | \
    python "$SCRIPT_DIR/generate/report.py" > /tmp/test_report.md
if grep -q "Test" /tmp/test_report.md; then
    echo "✓ PASS"
else
    echo "✗ FAIL"
    exit 1
fi

echo "=== All Tests Passed ==="
```

## 性能优化

### 缓存机制

```python
# scripts/utils/cache.py
"""简单的文件缓存机制"""
import hashlib
import json
import os
from functools import wraps

CACHE_DIR = os.path.expanduser('~/.cache/skill_scripts')

def get_cache_key(file_path, *args):
    """基于文件内容和参数生成缓存键"""
    with open(file_path, 'rb') as f:
        content_hash = hashlib.md5(f.read()).hexdigest()
    args_str = json.dumps(args, sort_keys=True)
    return hashlib.md5(f"{content_hash}:{args_str}".encode()).hexdigest()

def cached(func):
    """缓存装饰器"""
    @wraps(func)
    def wrapper(file_path, *args, **kwargs):
        cache_key = get_cache_key(file_path, *args)
        cache_file = os.path.join(CACHE_DIR, f"{cache_key}.json")

        # 检查缓存
        if os.path.exists(cache_file):
            with open(cache_file) as f:
                return json.load(f)

        # 执行并缓存结果
        result = func(file_path, *args, **kwargs)

        os.makedirs(CACHE_DIR, exist_ok=True)
        with open(cache_file, 'w') as f:
            json.dump(result, f)

        return result
    return wrapper

# 使用示例
# scripts/analyze/complexity.py
from utils.cache import cached

@cached
def calculate_complexity(file_path):
    # 复杂计算...
    return result
```

### 并行执行

```python
# scripts/analyze/parallel_scan.py
"""并行扫描多个文件"""
import multiprocessing
import sys
from pathlib import Path

from complexity import calculate_complexity
from dependencies import analyze_dependencies

def analyze_file(file_path):
    """分析单个文件"""
    result = {
        'file': file_path,
        'complexity': calculate_complexity(file_path),
        'dependencies': analyze_dependencies(file_path)
    }
    return result

def parallel_scan(file_paths, max_workers=None):
    """并行扫描多个文件"""
    with multiprocessing.Pool(max_workers) as pool:
        results = pool.map(analyze_file, file_paths)
    return results

if __name__ == '__main__':
    import json
    files = sys.argv[1:]
    results = parallel_scan(files)
    print(json.dumps(results, indent=2))
```

## 小结

scripts目录是Skill的"确定性引擎"，良好的组织和管理是Skill成功的关键：

**目录结构**：
- 按功能分层（analyze/、generate/、utils/）
- 清晰的命名规范（动词+名词）
- 模块化和可复用设计

**调用机制**：
- SKILL.md通过bash命令调用脚本
- 脚本间通过JSON格式传递数据
- 支持管道组合和参数传递

**质量保证**：
- 标准化的错误处理和日志
- 单元测试和集成测试
- 缓存和性能优化

记住，脚本是AI能力的延伸。一个好的脚本设计可以让AI专注于创造性工作，而将确定性任务交给可靠的工具处理。
