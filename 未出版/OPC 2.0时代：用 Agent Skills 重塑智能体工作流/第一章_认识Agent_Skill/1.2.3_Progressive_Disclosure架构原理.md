---
section_id: "1.2.3"
title: "Progressive Disclosure架构原理"
status: draft
word_count: 0
target_words: 4500
---

# 1.2.3 Progressive Disclosure架构原理

## 为什么需要渐进式披露

在深入技术细节之前，让我们先思考一个问题：**为什么Skill架构要设计成渐进式加载？为什么不能一次性加载所有内容？**

答案很简单：**资源是有限的，而需求是无限的**。

大语言模型的上下文窗口是有限的——即使是最先进的模型，也只能同时处理几十万Token。如果你安装了100个Skill，每个Skill的平均内容量是2000 Token，那么全部加载就需要20万Token，这已经接近甚至超过了大多数模型的上下文限制。

更糟糕的是，上下文窗口不仅存储Skill，还要存储：
- 对话历史
- 用户输入
- AI输出
- 工具调用结果
- 文件内容

如果不加选择地加载所有Skill，很快就会耗尽上下文空间，导致AI"失忆"——忘记早期的对话内容，甚至忘记Skill本身的指令。

渐进式披露（Progressive Disclosure）正是为了解决这个问题而设计的。它的核心思想是：**只在需要的时候加载必要的内容**。

## 渐进式披露的设计哲学

渐进式披露不是Agent Skill独有的概念，它最早出现在人机交互设计领域。

想象你打开一个复杂的软件，比如Photoshop。如果它一次性展示所有功能和选项，你会感到 overwhelmed。相反，Photoshop采用了渐进式披露：

- **第一层**：主界面只显示最常用的工具
- **第二层**：点击菜单可以看到更多选项
- **第三层**：打开对话框可以看到高级设置

每一层都建立在前一层的基础上，用户可以根据自己的需要深入探索，而不是被迫面对所有复杂性。

Agent Skill借鉴了这一设计理念，将其应用到AI上下文管理中：

- **第一层（元数据）**：让AI知道有哪些Skill可用
- **第二层（正文）**：当Skill被触发时，加载具体的执行指令
- **第三层（参考文档）**：在执行过程中，按需加载详细的参考资料

这种分层设计实现了三个关键目标：

**1. 可扩展性（Scalability）**

你可以安装任意数量的Skill，而不会影响系统性能。因为任何时候，只有被激活的Skill才会占用上下文空间。

**2. 高效性（Efficiency）**

Token使用被最小化。不需要为每个请求都发送庞大的Prompt，只需加载当前需要的Skill内容。

**3. 隔离性（Isolation）**

不同Skill之间互不干扰。每个Skill在自己的上下文中运行，不会因为其他Skill的存在而影响行为。

## 三级加载机制详解

让我们深入探讨三级加载机制的工作原理。

### Level 1：元数据感知（Metadata Awareness）

当Claude启动时，它会执行以下操作：

1. 扫描所有已安装的Skill目录
2. 读取每个Skill的SKILL.md文件
3. 只提取YAML Frontmatter部分（name和description）
4. 构建一个Skill注册表

这个注册表的数据结构大致如下：

```json
{
  "skills": [
    {
      "name": "code-reviewer",
      "description": "When the user asks to review code for quality, security, or best practices"
    },
    {
      "name": "doc-generator",
      "description": "When the user needs to generate documentation from code"
    },
    {
      "name": "test-writer",
      "description": "When the user asks to write unit tests for a function or module"
    }
  ]
}
```

注意，这个注册表只包含name和description，不包含SKILL.md的正文内容。这使得注册表非常轻量——即使安装了100个Skill，注册表的大小也只有几十KB。

**为什么description如此重要？**

description是Skill触发机制的核心。Claude使用description来判断何时应该激活某个Skill。

当你提出一个请求时，Claude会：
1. 分析你的请求语义
2. 与注册表中所有Skill的description进行匹配
3. 选择匹配度最高的Skill（如果有的话）
4. 只有当匹配度超过阈值时，才会激活该Skill

这种机制确保了Skill只在合适的场景下被调用，避免了误触发。

### Level 2：按需激活（On-Demand Activation）

当Claude决定使用某个Skill时，才会加载该Skill的完整内容。

加载的内容包括：
- YAML Frontmatter（完整的配置信息）
- Markdown正文（触发条件、执行步骤、输出规范）

这个过程发生在用户请求处理阶段。加载完成后，Skill的指令被注入到当前上下文中，Claude开始按照Skill的指示执行。

**关键点：Skill的执行是独立的**

通过`context: fork`机制，Skill在一个独立的上下文中执行。这意味着：
- Skill可以访问主对话的上下文（用于理解用户需求）
- 但Skill的执行不会影响主对话的状态
- 当Skill执行完毕后，只有结果返回主对话，中间过程被丢弃

这种隔离性带来了很多好处：

1. **避免上下文污染**：Skill执行过程中产生的大量中间信息不会占用主对话的上下文空间
2. **可重入性**：同一个Skill可以被多次调用，每次都有干净的上下文
3. **可组合性**：多个Skill可以顺序执行，彼此之间不会干扰

### Level 3：延迟加载（Lazy Loading）

有些Skill需要参考大量文档，比如：
- API参考手册
- 编码规范文档
- 示例代码库
- 配置选项说明

如果这些文档都塞进SKILL.md正文，会导致正文过长，影响加载性能。因此，Agent Skill引入了references/目录，用于存放这些参考文档。

**延迟加载的工作流程**：

1. Skill开始执行时，只加载SKILL.md正文
2. 执行过程中，当遇到需要查阅参考文档的情况，Claude会主动调用读取工具
3. 只加载被引用的部分，而不是整个文档
4. 加载的内容临时添加到当前上下文，执行完毕后丢弃

这种设计让Skill可以拥有海量的参考资料，而不会影响性能。

**一个实际的例子**：

假设你有一个处理PDF的Skill，它需要参考一个50页的PDF处理规范文档。

- 如果你一次性把整个规范塞进Prompt，需要约15,000 Token
- 使用Skill的延迟加载机制：
  - SKILL.md正文（加载）：500 Token
  - 规范文档第3章关于表格处理的部分（按需加载）：2000 Token
  - 规范文档第7章关于OCR的部分（按需加载）：1500 Token
  - 总计：4000 Token，节省了73%

## 上下文隔离：context fork机制

context fork是渐进式披露架构的关键技术之一。让我们详细理解它的工作原理。

### 什么是Context Fork

在操作系统中，fork是一个创建新进程的系统调用。子进程继承父进程的内存空间，但随后的修改互不影响。

Agent Skill借鉴了这一概念。当Skill被激活时：
1. 从主对话"fork"出一个子上下文
2. 子上下文继承主对话的部分状态（如用户信息、项目背景）
3. 在子上下文中加载Skill的指令
4. Skill在子上下文中执行，与主对话隔离
5. 执行完成后，子上下文被销毁，结果返回主对话

### 为什么需要隔离

**场景一：避免信息污染**

假设你在和Claude讨论一个项目架构问题，中途调用了一个代码生成Skill。如果Skill的执行污染了主对话的上下文，可能会导致：
- Skill生成的临时变量名出现在后续对话中
- Skill的错误处理逻辑影响了主对话的回答风格
- Skill引用的参考文档占据了上下文空间，导致主对话"失忆"

通过context fork，这些问题都被避免了。

**场景二：支持并发执行**

如果你需要同时处理多个独立的子任务，context fork让每个任务都有自己的上下文：

```
主对话："帮我审查这三个文件：app.py、utils.py、models.py"

→ fork 上下文 A，加载 code-reviewer Skill，审查 app.py
→ fork 上下文 B，加载 code-reviewer Skill，审查 utils.py
→ fork 上下文 C，加载 code-reviewer Skill，审查 models.py

等待三个审查完成
合并结果返回给用户
```

三个审查并行进行，互不干扰。

### 配置Context Fork

在SKILL.md中，可以通过`context`字段控制fork行为：

```yaml
---
name: code-reviewer
context: fork  # 在独立上下文中执行
---
```

如果不设置`context: fork`，Skill会在主对话上下文中执行。这在某些场景下是有用的，比如：
- Skill只是提供一些快捷指令，不需要复杂的隔离
- Skill需要和主对话共享状态
- Skill是轻量级的，不会占用太多上下文

但大多数情况下，建议设置`context: fork`，以获得更好的隔离性和可预测性。

## 生命周期钩子：Lifecycle Hooks

Claude Code 2.1引入了生命周期钩子机制，让Skill可以在特定事件发生时执行自定义逻辑。

### 可用的钩子

**onLoad**：Skill加载时触发

用于执行初始化操作，比如：
- 加载配置文件
- 初始化变量
- 检查前置条件

```yaml
---
name: deploy-app
hooks:
  onLoad: |
    # 检查是否在Git仓库中
    if ! git rev-parse --git-dir > /dev/null 2>&1; then
      echo "Error: Not a git repository"
      exit 1
    fi
---
```

**preToolUse**：调用工具前触发

用于权限检查、日志记录、参数校验等：

```yaml
---
name: database-query
allowed-tools: [mcp-postgres/query]
hooks:
  preToolUse: |
    # 记录所有数据库查询
    echo "[$(date)] Query: $1" >> query.log

    # 检查是否为危险操作
    if echo "$1" | grep -iE "(drop|delete|truncate)"; then
      echo "Warning: Destructive operation detected"
      # 可以在这里添加额外的确认逻辑
    fi
---
```

**onError**：执行出错时触发

用于错误恢复、重试、通知等：

```yaml
---
name: api-caller
hooks:
  onError: |
    # 记录错误日志
    echo "Error occurred: $ERROR_MESSAGE" >> error.log

    # 如果是网络错误，自动重试
    if echo "$ERROR_MESSAGE" | grep -q "timeout"; then
      sleep 5
      RETRY=true
    fi
---
```

### 钩子的执行环境

钩子在Skill的fork上下文中执行，可以访问：
- 当前上下文的所有变量
- 工具调用接口
- 环境变量

但钩子不能修改Skill的主逻辑，它们只是"观察者"和"拦截器"。

## 性能数据与优化建议

让我们看一些实际的性能数据，了解渐进式披露架构的效果。

### 加载时间对比

假设安装了50个Skill，每个Skill平均：
- Frontmatter：150 Token
- 正文：1500 Token
- 参考文档：5000 Token（按需加载）

**传统方式**（一次性加载所有内容）：
- 总Token数：50 × (150 + 1500 + 5000) = 332,500 Token
- 加载时间：约10-15秒（取决于网络）
- 内存占用：约500MB

**渐进式披露**（只加载元数据）：
- 初始Token数：50 × 150 = 7,500 Token
- 加载时间：< 1秒
- 内存占用：约50MB

**按需激活时**（加载一个Skill）：
- Token数：150 + 1500 = 1,650 Token
- 加载时间：< 100ms
- 额外内存：约10MB

### 上下文窗口占用对比

在100轮对话后：

**不使用Skill隔离**：
- 对话历史：约15,000 Token
- 所有加载过的Skill内容：约30,000 Token（累积）
- 工具调用结果：约10,000 Token
- **总计：55,000 Token**，接近上下文上限

**使用Skill隔离**：
- 对话历史：约15,000 Token
- 当前激活的Skill：约1,500 Token
- 主对话不会累积Skill内容
- **总计：16,500 Token**，空间充足

### 优化建议

基于以上数据，我们可以得出一些优化建议：

**1. 保持Frontmatter精简**

Frontmatter在启动时就会加载，应该尽可能精简。只保留name、description等必要字段，详细的说明放在正文或references中。

**2. 合理使用references**

对于大量参考文档，使用references/目录而不是塞进正文。这样可以：
- 减少初始加载时间
- 只加载需要的部分
- 支持文档的热更新（修改reference文件不需要重启）

**3. 使用context fork**

对于复杂的、多步骤的Skill，使用`context: fork`隔离执行环境。这可以：
- 避免上下文污染
- 提高可预测性
- 支持并发执行

**4. 设计合理的触发条件**

description的准确性直接影响Skill的触发效率。一个好的description应该：
- 明确说明Skill的用途
- 包含常见的触发场景
- 避免过于宽泛（导致误触发）或过于狭窄（导致漏触发）

## 渐进式披露与传统方案的对比

让我们把渐进式披露架构与传统的Prompt方案进行详细对比：

| 维度 | 传统Prompt | 渐进式披露（Skill） |
|------|-----------|-------------------|
| **初始加载** | 每次都要发送完整Prompt | 只加载元数据（150 Token） |
| **激活开销** | N/A（总是激活） | 按需加载正文（1000-2000 Token） |
| **上下文占用** | 累积增长，无上限 | 隔离环境，可预测 |
| **并发能力** | 单线程，顺序执行 | 支持fork，可并行 |
| **可扩展性** | 受限于上下文窗口 | 可安装任意数量Skill |
| **隔离性** | 无隔离，相互影响 | 完全隔离，互不干扰 |
| **调试难度** | 高（难以追踪） | 低（独立的执行日志） |
| **版本控制** | 困难 | 天然支持（Git管理） |

从对比可以看出，渐进式披露架构在几乎所有维度上都优于传统Prompt方案。这就是为什么Agent Skill能够同时实现"强大功能"和"高效性能"的原因。

## 小结

渐进式披露是Agent Skill的核心技术架构，它通过三级加载机制（元数据→正文→参考文档）和上下文隔离（context fork），实现了可扩展性、高效性和隔离性的完美平衡。

理解这一架构的工作原理，对于编写高质量的Skills至关重要。它帮助你：
- 设计合理的Skill结构
- 优化加载性能
- 避免常见的上下文管理陷阱
- 充分利用hooks等高级特性

在下一节，我们将探讨Agent Skill与其他AI概念（MCP、Subagents、Command）的关系和区别。
