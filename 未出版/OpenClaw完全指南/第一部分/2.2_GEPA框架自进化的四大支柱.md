---
section_id: 2.2
title: GEPA框架自进化的四大支柱
status: draft
target_words: 2500
word_count: 0
---

# GEPA框架：自进化的四大支柱

## 一个循环，无限进化

想象你正在教一个实习生如何完成一项工作：

**第一次**：你让他写一个报告。他写完后，你发现格式不对、数据有误、结论不够深入。你给他反馈，他修改。

**第二次**：他再次写报告。这次格式对了，但数据分析还是不够。你继续反馈，他继续改。

**第三次**：他已经能写出合格的报告了。你稍微提点一下，他就能交出高质量的成果。

**第十次**：他已经完全掌握了这个任务，甚至能主动发现你没有提到的问题，提出你没有想到的建议。

这就是自进化的过程——通过"执行→评估→反思→进化"的循环，不断积累经验，持续改进能力。

OpenClaw的核心架构，正是围绕这个循环设计的。我们可以将其归纳为GEPA框架：

| 支柱 | 英文 | 含义 | OpenClaw中的实现 |
|-----|------|------|-----------------|
| G | Generation | 执行与生成 | 通过Agent执行Shell、浏览器操作 |
| E | Evaluation | 评估与打分 | 检查命令输出、判断任务是否成功 |
| P | Planning | 诊断与反思 | 失败时自动分析错误日志、修正尝试 |
| A | Advancement | 进化与更新 | 安装新Skill、存储成功经验到记忆库 |

## G - Generation（执行与生成）

这是自进化循环的起点：AI必须能够实际执行动作。

传统AI只能"说"，不能"做"。你问它"怎么订机票"，它会告诉你步骤，但不会真的帮你订。

OpenClaw完全不同。它通过Pi Agent（主代理）调用各种工具，真正执行操作：

### 1. Shell命令执行

```bash
# 让OpenClaw查看系统信息
"帮我看看今天有哪些系统更新"

→ OpenClaw执行：brew outdated
→ 分析输出，告诉你有哪些包可以更新
→ 询问是否要更新
```

### 2. 浏览器自动化

```bash
# 让OpenClaw帮你查资料
"查一下明天北京到上海的机票，最便宜的是哪家"

→ OpenClaw打开浏览器
→ 访问携程/去哪儿等网站
→ 输入查询条件
→ 抓取价格信息
→ 对比后告诉你答案
```

### 3. 文件系统操作

```bash
# 让OpenClaw管理文件
"把下载文件夹里所有PDF整理到'文档'文件夹，按年份分类"

→ OpenClaw扫描下载文件夹
→ 识别所有PDF文件
→ 读取文件创建日期
→ 创建年份子文件夹（2024、2023等）
→ 移动文件到对应位置
→ 生成整理报告
```

### Ralph循环：保持"满血状态"

OpenClaw使用了一种称为Ralph循环的模式来确保生成质量：

- 每个生成步骤都启动一个新的、无历史包袱的Agent实例
- 只读取当前任务所需的文件（如prd.json）
- 避免长对话导致的遗忘或幻觉
- 确保生成过程处于"满血状态"

这就像让实习生每次执行任务时，都带着最清晰的头脑和最新的信息。

## E - Evaluation（评估与打分）

执行完成后，必须评估结果。这是自进化的关键一步——AI需要知道它做得好不好。

OpenClaw通过多层级的评估机制来实现这一点：

### 1. 自我修复（Self-Correction）

当Agent执行Shell命令或代码出错时，OpenClaw会：

- 捕获错误输出（Stderr）
- 分析错误原因：是权限问题？路径不存在？命令语法错误？
- 自主尝试修复：修正命令、创建缺失的目录、调整参数
- 重试直到成功

**例子**：

```bash
# 第一次尝试
$ cp file1.txt /backup/
→ Error: /backup/ directory does not exist

# AI分析错误，创建目录，重试
$ mkdir -p /backup/ && cp file1.txt /backup/
→ Success!
```

这种"试错-修正"循环是OpenClaw能够夜间自动修Bug的基础。

### 2. 多智能体互查（Peer Review）

在Antfarm架构中，引入了验证员（Verifier）和审查员（Reviewer）角色：

- 程序员Agent写完代码后，不能自己通过
- 必须交给独立的验证员Agent审查
- 验证员根据规划阶段制定的"验收标准"逐条检查
- 如果验证不通过，流程回退重试或暂停等待人类干预

这就好比代码审查（Code Review），避免"自欺欺人"。

### 3. 审批门控（Approval Gates）

对于关键操作，Lobster引擎支持设置`approval: required`：

```yaml
steps:
  - action: send_email
    approval: required  # 这里会暂停，等待人工批准
    params:
      to: boss@company.com
      subject: "辞职信"
```

工作流运行到此处会暂停并生成一个Resume Token，必须经人类批准后才能继续执行。

## P - Planning（诊断与反思）

评估发现问题后，需要规划如何改进。这是自进化的"大脑"。

OpenClaw通过两种方式进行规划：

### 1. Lobster引擎（确定性规划）

对于成熟的任务流程，OpenClaw使用Lobster宏引擎将其定义为确定性的YAML管道：

```yaml
name: "每日新闻简报"
steps:
  - action: fetch
    url: "https://news.example.com"
  - action: extract
    method: llm
    prompt: "提取重要新闻标题和摘要"
  - action: summarize
    method: llm
    prompt: "生成300字的新闻简报"
  - action: save
    path: "/docs/daily_news.md"
```

这种规划的优势：
- 确定性：每次执行都遵循相同的步骤
- 可预测：不会出现"幻觉"或随机行为
- 高效：节省Token，降低延迟

### 2. Antfarm规划师（自主规划）

对于模糊的需求，规划师（Planner）角色会将其拆解为具体的"用户故事"和验收标准：

**例子**：

你下达指令："增加用户登录功能"

规划师会将其拆解为：
1. 设计用户数据库表结构
2. 实现注册API
3. 实现登录API
4. 添加密码加密
5. 实现JWT令牌认证
6. 编写前端登录界面
7. 编写单元测试
8. 集成测试

每个子任务都有明确的验收标准，为后续的执行和评估提供依据。

## A - Advancement（进化与更新）

最后一步，也是最关键的一步——将经验固化为能力。

OpenClaw通过两种方式实现进化：

### 1. 持久记忆（Persistent Memory）

OpenClaw不会像普通Chatbot那样聊完即忘。它将成功经验写入：

- MEMORY.md：长期记忆，存储用户画像和历史交互
- USER.md：用户偏好，存储个人习惯和设置
- PROJECT_*.md：项目记忆，存储各个项目的上下文
- SQLite向量数据库：用于语义检索和相似度匹配

通过混合检索（向量+关键词），Agent在处理新任务时能调用过去的经验，实现能力的累积。

### 2. 技能自构建（Self-Programming）

OpenClaw最神奇的能力之一，是编写自身的技能。

如果用户要求的任务超出了现有能力，Agent可以：

1. 分析任务需求：理解要完成什么，需要什么工具
2. 编写SKILL.md：创建技能定义文件，描述功能和使用场景
3. 编写执行脚本：实现具体的执行逻辑（Python/Bash）
4. 热加载到系统：不需要重启，新技能立即生效

**例子**：

你发现OpenClaw不会操作Replicator API。于是你告诉它：

"帮我连接Replicator API，提取销售数据"

OpenClaw发现没有这个能力，于是：

1. 分析Replicator API的文档
2. 编写一个新的`replicator_skill/SKILL.md`
3. 编写Python脚本实现API调用
4. 将技能保存到`~/.openclaw/workspace/skills/`
5. 热加载，立即可以使用

从此以后，OpenClaw永久性地获得了这个能力。你随时可以说：

"用Replicator API查一下上个月的销售数据"，它会直接执行。

## GEPA循环：越用越强

将四个支柱串联起来，就是OpenClaw的自进化循环：

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   Planning（规划）                                      │
│   ↓                                                     │
│   Generation（执行）                                    │
│   ↓                                                     │
│   Evaluation（评估）                                    │
│   ↓                                                     │
│   Advancement（进化）                                   │
│   ↓                                                     │
│   （回到Planning，循环往复）                            │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

**第一次循环**：AI尝试执行任务，可能犯错，评估发现问题，规划改进方案，将经验存入记忆。

**第十次循环**：AI已经掌握了任务的要领，能够高效完成，甚至发现更优的方法，更新技能和记忆。

**第一百次循环**：AI已经成为这个任务的专家，能够处理各种边界情况，甚至主动提出优化建议。

这就是自进化的力量——不是通过训练数据更新，而是通过每一次实际交互实时学习和进化。

---

**本章小结**

- GEPA框架：Generation（执行）、Evaluation（评估）、Planning（规划）、Advancement（进化）
- Generation：Pi Agent调用工具，Ralph循环保持"满血状态"
- Evaluation：自我修复、多智能体互查、审批门控
- Planning：Lobster确定性规划、Antfarm规划师自主拆解
- Advancement：持久记忆、技能自构建
- 循环往复，越用越强
