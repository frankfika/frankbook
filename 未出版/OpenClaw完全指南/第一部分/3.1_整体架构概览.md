---
section_id: 3.1
title: 整体架构概览
status: draft
target_words: 2000
word_count: 2100
---

# 整体架构概览

## 从"能用"到"好用"的架构演进

如果你用过早期的AI工具，一定经历过这种痛苦：

每次对话都是独立的，AI不记得你是谁；每次执行任务都要重新解释背景；复杂的任务经常中途"跑偏"；敏感操作不敢让AI碰...

OpenClaw的架构设计，正是为了解决这些痛点而生。

## Gateway-Centric：以网关为中心的星型拓扑

OpenClaw采用了一种称为Gateway-Centric（以网关为中心）的架构模式。

想象一个星型拓扑结构：

```
┌─────────────────────────────────────────────────────────────┐
│                        用户层                                │
│  ┌─────────┐  ┌─────────┐  ┌─────────┐  ┌─────────┐        │
│  │WhatsApp │  │Telegram │  │ Discord │  │ Web UI  │        │
│  └────┬────┘  └────┬────┘  └────┬────┘  └────┬────┘        │
└───────┼────────────┼────────────┼────────────┼──────────────┘
        │            │            │            │
        └────────────┴─────┬──────┴────────────┘
                           │ WebSocket
                    ┌──────┴──────┐
                    │   Gateway   │ ← 127.0.0.1:18789
                    │  (中枢神经)  │
                    └──────┬──────┘
                           │
        ┌──────────────────┼──────────────────┐
        │                  │                  │
        │ RPC              │ 调用              │ 加载
        ↓                  ↓                  ↓
┌───────────────┐  ┌───────────────┐  ┌───────────────┐
│   Pi Agent    │  │   Lobster     │  │    Skills     │
│   (AI大脑)    │  │   (工作流引擎) │  │   (能力插件)   │
└───────┬───────┘  └───────────────┘  └───────────────┘
        │
        ↓ 调用
┌───────────────────────────────────────────────────────────┐
│                      工具层                                │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐  │
│  │ 文件系统  │  │  Shell   │  │  浏览器   │  │   MCP    │  │
│  └──────────┘  └──────────┘  └──────────┘  └──────────┘  │
└───────────────────────────────────────────────────────────┘
                           │
                    ┌──────┴──────┐
                    │ Docker沙箱  │ ← 隔离非主会话
                    └─────────────┘
```

在这个架构中，Gateway（网关）是整个系统的"中枢神经"：

- 连接中心：所有的外部客户端（WhatsApp、Telegram、Web UI、CLI）以及内部组件（Agent、Skills）都必须连接到Gateway进行通信
- 会话管理：维护所有会话状态，将不同渠道的消息路由给正确的Agent实例
- 任务调度：内置Cron调度器，触发定时任务
- 事件总线：处理Webhook回调和系统事件

### WebSocket连接管理

Gateway运行一个WebSocket服务器，默认监听`127.0.0.1:18789`。

为什么是WebSocket而不是HTTP？

```
传统HTTP：
客户端 ────请求────> 服务器
客户端 <───响应──── 服务器
（每次都要重新建立连接，只能客户端主动）

WebSocket：
客户端 <═══════════> 服务器
（保持长连接，双向通信，服务器可主动推送）
```

WebSocket的优势：
- 实时性：消息毫秒级到达
- 低延迟：不需要频繁建立连接
- 双向通信：AI可以主动推送消息给你（比如"任务完成了"）

## Loopback-First：默认安全的设计哲学

如果你注意到了，Gateway默认绑定的是`127.0.0.1`（本地回环地址），而不是`0.0.0.0`（所有网卡）。

这不是巧合，而是Loopback-First（本地回环优先）的安全策略。

```
绑定 0.0.0.0:18789  →  任何人都能访问（危险！）
绑定 127.0.0.1:18789 →  只有本机能访问（安全）
```

这种设计的考量是：

OpenClaw拥有系统级权限——它可以读写你的文件、执行Shell命令、控制浏览器。如果暴露在公网，后果不堪设想。

那么，如何远程访问？

官方推荐的方案：
- SSH隧道：`ssh -L 18789:localhost:18789 user@server`
- Tailscale：安全的内网穿透工具

而不是直接把端口暴露到公网。

## DM Pairing：私信配对机制

由于OpenClaw拥有系统级权限，它不会响应陌生人的消息。

这就是DM Pairing（私信配对）机制的作用：

```
陌生人发送消息 ────> Gateway拦截
                          │
                          ↓
                    生成6位配对码
                    发送给陌生人
                          │
                          ↓
管理员执行命令：
openclaw pairing approve telegram 123456
                          │
                          ↓
                    配对成功
                    陌生人加入白名单
```

**工作流程**：

1. 当一个未授权的账号（比如Telegram上的陌生人）向你的Bot发送消息时，系统会拦截该消息
2. 系统生成一个6位数的配对码，发送给对方
3. 拥有终端权限的管理员执行`openclaw pairing approve <channel> <code>`来批准
4. 只有配对成功的用户才能触发Agent执行任务

这是一种"默认拒绝"的安全模型——除非你明确授权，否则任何人都不能控制你的OpenClaw。

## Pi Agent：系统的大脑

Pi Agent是OpenClaw的"大脑"，负责逻辑推理和任务执行。

### RPC通信模式

Agent不直接运行在Gateway进程中，而是通过RPC（远程过程调用）与Gateway通信。

```
Gateway进程                     Agent进程
    │                               │
    │ <─────── RPC调用 ──────────> │
    │                               │
    │ <─────── RPC响应 ──────────> │
```

这种解耦设计的好处：
- Agent可以在不同的进程甚至不同的设备上运行
- Agent崩溃不会影响Gateway的稳定性
- 可以运行多个Agent实例，实现负载均衡

### 流式工具调用（Tool Streaming）

这是Pi Agent最核心的特性之一。

**传统模式**：
```
LLM开始生成 ────> 生成完整回复 ────> 执行工具 ────> 返回结果
     (等待...)        (等待...)        (执行)
```

**流式模式**：
```
LLM开始生成 ────> 识别到工具调用 ────> 立即执行 ────> 继续生成
     (同时进行，边生成边执行)
```

**例子**：

用户说："读取config.json文件，然后告诉我里面有什么配置"

传统模式：LLM生成完整的回复，然后执行读取，再生成新回复（2-3次往返）

流式模式：LLM刚生成"让我读取文件..."，Agent就立即执行读取，将结果注入上下文，LLM继续生成分析（1次完成）

这种机制大幅降低了复杂任务的响应延迟。

## 模型无关性：不绑定任何供应商

OpenClaw不绑定任何特定的LLM供应商。它支持：

| 供应商 | 支持的模型 |
|-------|----------|
| Anthropic | Claude 3.5 Sonnet, Claude Opus |
| OpenAI | GPT-4o, GPT-4 Turbo |
| Google | Gemini 1.5 Pro, Gemini 2.0 |
| 阿里云 | Qwen-Max, Qwen-Plus |
| DeepSeek | DeepSeek-V3 |
| 本地部署 | Llama 3, Ollama |

### 抽象层设计

系统内部定义了一套统一的Provider接口，将不同厂商的API差异抹平：

```json
// openclaw.json 配置示例
{
  "models": {
    "main": "claude-3-5-sonnet",
    "fallback": "gpt-4o",
    "local": "ollama:llama3"
  },
  "providers": {
    "anthropic": {...},
    "openai": {...},
    "ollama": {...}
  }
}
```

你甚至可以在对话中动态切换模型：

```
你：用本地模型帮我分析这个文件（隐私敏感）
OpenClaw：好的，切换到 ollama:llama3...

你：用最强模型帮我写代码
OpenClaw：好的，切换到 claude-3-5-sonnet...
```

## Docker沙箱：隔离不信任的输入

如果Agent执行的命令来自群聊或其他不受信任的渠道，怎么办？

OpenClaw引入了Docker沙箱机制。

```json
// 沙箱配置
{
  "agents": {
    "defaults": {
      "sandbox": {
        "mode": "non-main"
      }
    }
  }
}
```

**Non-Main隔离模式**：

| 会话类型 | 运行环境 | 权限 |
|---------|---------|------|
| 主会话（你自己的） | 宿主机 | 完全控制 |
| 非主会话（群聊、其他用户） | Docker容器 | 受限 |

在沙箱内：
- 只能访问受限的文件系统（通常是只读的）
- 无法调用宿主机的敏感工具（如浏览器控制）
- 网络访问受限

这种设计让OpenClaw可以在多用户场景下安全运行。

---

**本节小结**

- OpenClaw采用Gateway-Centric架构，Gateway是系统中枢
- WebSocket实现实时双向通信，默认端口18789
- Loopback-First策略确保服务不暴露到公网
- DM Pairing机制防止未授权访问
- Pi Agent是系统大脑，支持流式工具调用
- 模型无关性设计，支持多种LLM
- Docker沙箱隔离不信任的输入
