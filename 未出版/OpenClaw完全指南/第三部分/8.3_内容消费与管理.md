---
section_id: 8.3
title: 内容消费与管理
status: draft
target_words: 2000
word_count: 2080
---

# 内容消费与管理

在信息时代，我们每天都在消费大量的内容：文章、视频、播客、论文、社交媒体动态等。然而，面对海量的内容，我们往往感到 overwhelmed——收藏夹里堆积着数百篇"稍后阅读"的文章，订阅的频道更新频繁却无暇观看，重要的资料散落在各个应用中难以检索。OpenClaw 可以帮助我们构建一个智能内容管理系统，实现内容的自动收集、智能分类、摘要提取和个性化推荐。

## 场景介绍

### 内容消费的痛点

1. **信息过载**：每天产生的内容远超我们的消费能力
2. **分散存储**：内容散落在浏览器书签、笔记应用、社交媒体等各处
3. **难以检索**：需要时找不到之前看过的内容
4. **阅读压力**：收藏的内容越积越多，造成心理负担
5. **质量参差不齐**：需要花费大量时间筛选有价值的内容

### OpenClaw 的解决方案

- **智能收集**：自动从多个渠道收集你感兴趣的内容
- **自动分类**：使用 AI 对内容进行主题分类和标签化
- **摘要生成**：提取文章核心观点，帮助你快速判断是否深入阅读
- **知识库构建**：将消费过的内容整理成结构化的知识库
- **个性化推荐**：基于你的阅读历史和兴趣，推荐相关内容

## 实现思路

内容管理系统的核心架构包括：

1. **内容采集层**：通过 RSS、API、浏览器插件等方式收集内容
2. **内容处理层**：清洗、去重、分类、摘要、标签化
3. **存储层**：将处理后的内容存入知识库
4. **检索层**：提供全文搜索和语义搜索能力
5. **推荐层**：基于用户画像推荐相关内容

这些组件可以通过 Lobster 工作流串联，形成一个自动化的内容处理流水线。

## 配置步骤

### 第一步：创建内容采集 Skill

```yaml
# ~/.openclaw/skills/content-curator/SKILL.md
---
name: content-curator
description: 内容策展助手
commands:
  - name: fetch-rss
    description: 抓取 RSS 订阅源
    script: |
      curl -s "{{feed.url}}" | \
        python3 -c "
import sys
import xml.etree.ElementTree as ET
import json

xml_content = sys.stdin.read()
root = ET.fromstring(xml_content)
items = []
for item in root.findall('.//item'):
    items.append({
        'title': item.find('title').text if item.find('title') is not None else '',
        'link': item.find('link').text if item.find('link') is not None else '',
        'description': item.find('description').text if item.find('description') is not None else '',
        'pubDate': item.find('pubDate').text if item.find('pubDate') is not None else ''
    })
print(json.dumps(items[:20]))
"

  - name: fetch-article
    description: 获取文章内容
    script: |
      # 使用 readability 提取正文
      curl -s "{{url}}" | \
        python3 -c "
import sys
from readability import Document
import json

html = sys.stdin.read()
doc = Document(html)
print(json.dumps({
    'title': doc.title(),
    'content': doc.summary(),
    'text': doc.summary()
}))
" 2>/dev/null || echo '{"error": "failed to fetch"}'

  - name: save-to-db
    description: 保存内容到数据库
    script: |
      sqlite3 ~/.openclaw/data/content.db <<EOF
        INSERT OR REPLACE INTO articles
        (id, title, url, content, summary, tags, source, created_at, status)
        VALUES (
          '$(echo "{{article.url}}" | md5)',
          '{{article.title}}',
          '{{article.url}}',
          '{{article.content}}',
          '{{article.summary}}',
          '{{article.tags}}',
          '{{article.source}}',
          datetime('now'),
          'unread'
        );
      EOF
```

### 第二步：创建内容分析 Agent

```yaml
# ~/.openclaw/agents/content-analyzer.yaml
name: content-analyzer
description: 内容分析与摘要专家
system_prompt: |
  你是一位专业的内容分析师，擅长快速理解文章主旨并提取关键信息。

  任务要求：
  1. 生成一句话摘要（不超过50字）
  2. 提取3-5个核心观点
  3. 标注内容类型（技术/商业/人文/新闻/教程等）
  4. 评估阅读价值（1-5星）
  5. 建议阅读深度（略读/精读/收藏）

  输出格式（JSON）：
  {
    "summary": "一句话摘要",
    "key_points": ["观点1", "观点2", "观点3"],
    "category": "内容类型",
    "rating": 4,
    "recommendation": "精读",
    "tags": ["标签1", "标签2"]
  }
```

### 第三步：编写内容管理工作流

```yaml
# ~/.openclaw/workflows/content-pipeline.lobster
name: content-pipeline
version: "1.0"

triggers:
  - type: schedule
    cron: "0 */2 * * *"  # 每2小时执行一次
  - type: webhook
    path: "/content/add"

steps:
  # 1. 获取 RSS 订阅更新
  - name: fetch_feeds
    skill: content-curator
    command: fetch-rss
    loop:
      over: "{{user.rss_feeds}}"
      var: feed
    args:
      feed: "{{feed}}"

  # 2. 去重检查
  - name: deduplicate
    skill: database
    command: query
    args:
      sql: |
        SELECT url FROM articles
        WHERE url IN ({{steps.fetch_feeds.output.*.link}})

  # 3. 获取新文章内容
  - name: fetch_articles
    skill: content-curator
    command: fetch-article
    loop:
      over: "{{steps.fetch_feeds.output}}"
      condition: "{{item.link not in steps.deduplicate.output}}"
      var: item
    args:
      url: "{{item.link}}"

  # 4. 分析内容
  - name: analyze_content
    agent: content-analyzer
    loop:
      over: "{{steps.fetch_articles.output}}"
      var: article
    prompt: |
      请分析以下文章内容：
      标题：{{article.title}}
      内容：{{article.content | truncate: 3000}}

  # 5. 保存到知识库
  - name: save_articles
    skill: content-curator
    command: save-to-db
    loop:
      over: "{{steps.analyze_content.output}}"
      var: analysis
    args:
      article:
        title: "{{analysis.original_title}}"
        url: "{{analysis.original_url}}"
        content: "{{analysis.original_content}}"
        summary: "{{analysis.summary}}"
        tags: "{{analysis.tags | join: ','}}"
        source: "{{analysis.feed_name}}"

  # 6. 生成阅读列表
  - name: generate_digest
    agent: content-curator
    condition: "{{steps.analyze_content.output | length > 0}}"
    prompt: |
      基于以下新收录的文章，生成今日阅读推荐：
      {{steps.analyze_content.output}}

      请按以下格式输出：
      1. 必读（5星推荐）
      2. 值得一看（4星推荐）
      3. 快速浏览（3星及以下）

  # 7. 推送通知
  - name: notify_user
    skill: notification
    command: send
    condition: "{{steps.analyze_content.output | length > 0}}"
    args:
      channel: "{{user.preferences.notification_channel}}"
      title: "新内容提醒（{{steps.analyze_content.output | length}}篇）"
      content: "{{steps.generate_digest.output}}"
```

### 第四步：配置 RSS 订阅源

```yaml
# ~/.openclaw/config.yaml
content:
  rss_feeds:
    - name: "阮一峰的网络日志"
      url: "http://www.ruanyifeng.com/blog/atom.xml"
      category: "技术"
    - name: "机器之心"
      url: "https://www.jiqizhixin.com/rss"
      category: "AI"
    - name: "36氪"
      url: "https://36kr.com/feed"
      category: "商业"
    - name: "Solidot"
      url: "https://www.solidot.org/index.rss"
      category: "科技新闻"

  preferences:
    auto_archive_days: 30  # 30天后自动归档
    digest_time: "08:00"   # 每日摘要推送时间
    max_daily_articles: 10 # 每日最多推荐文章数
```

## 实际案例

### 案例一：技术博客阅读助手

程序员小李订阅了数十个技术博客，使用 OpenClaw 管理他的阅读清单：

```yaml
name: tech-reading-assistant

triggers:
  - type: schedule
    cron: "0 8 * * *"  # 每天早上8点

steps:
  - name: collect_tech_feeds
    skill: content-curator
    command: fetch-rss
    loop:
      over: "{{user.tech_feeds}}"

  - name: filter_by_interest
    agent: content-filter
    prompt: |
      根据用户技术栈偏好过滤文章：
      用户技术栈：{{user.tech_stack}}
      文章列表：{{steps.collect_tech_feeds.output}}

      只保留与用户技术栈相关的文章。

  - name: generate_tech_digest
    agent: tech-writer
    prompt: |
      为程序员生成技术早报：
      {{steps.filter_by_interest.output}}

      格式要求：
      ## 今日技术动态

      ### 前端
      - [文章标题](链接) - 一句话摘要

      ### 后端
      - [文章标题](链接) - 一句话摘要

      ### AI/ML
      - [文章标题](链接) - 一句话摘要

  - name: send_digest
    skill: notification
    command: send-email
    args:
      to: "{{user.email}}"
      subject: "技术早报 - {{today}}"
      body: "{{steps.generate_tech_digest.output}}"
```

### 案例二：论文阅读管理

研究生小王需要跟踪学术领域的最新论文：

```yaml
name: paper-tracker

triggers:
  - type: schedule
    cron: "0 9 * * 1"  # 每周一早上9点

steps:
  - name: search_arxiv
    skill: academic
    command: search-arxiv
    args:
      query: "{{user.research_keywords}}"
      date_range: "last_week"
      categories: ["cs.AI", "cs.CL", "cs.LG"]

  - name: download_papers
    skill: academic
    command: download-pdf
    loop:
      over: "{{steps.search_arxiv.output}}"

  - name: analyze_papers
    agent: research-assistant
    prompt: |
      请分析以下论文，生成研究摘要：
      论文标题：{{paper.title}}
      摘要：{{paper.abstract}}

      请提供：
      1. 研究问题
      2. 方法概述
      3. 主要贡献
      4. 与相关工作的关系
      5. 是否值得精读（是/否）

  - name: update_zotero
    skill: zotero
    command: add-items
    args:
      papers: "{{steps.analyze_papers.output}}"
      collection: "{{user.research_topic}}"

  - name: generate_weekly_report
    agent: research-assistant
    prompt: |
      基于本周新论文，生成研究周报：
      {{steps.analyze_papers.output}}

      请总结：
      1. 本周研究热点
      2. 值得关注的新方法
      3. 建议阅读的论文列表
```

### 案例三：视频内容管理

视频创作者小张需要跟踪行业内的优质视频内容：

```yaml
name: video-content-manager

triggers:
  - type: webhook
    path: "/video/bookmark"

steps:
  - name: extract_video_info
    skill: video
    command: extract-metadata
    args:
      url: "{{input.video_url}}"

  - name: transcribe_video
    skill: video
    command: generate-transcript
    args:
      video_id: "{{steps.extract_video_info.output.id}}"

  - name: analyze_transcript
    agent: content-analyzer
    prompt: |
      基于以下视频字幕，生成内容摘要：
      视频标题：{{steps.extract_video_info.output.title}}
      字幕：{{steps.transcribe_video.output}}

      请提供：
      1. 视频主题
      2. 核心观点（3-5点）
      3. 适合人群
      4. 内容质量评分

  - name: save_to_notion
    skill: notion
    command: add-page
    args:
      database: "视频库"
      properties:
        标题: "{{steps.extract_video_info.output.title}}"
        URL: "{{input.video_url}}"
        摘要: "{{steps.analyze_transcript.output.summary}}"
        标签: "{{steps.analyze_transcript.output.tags}}"
        状态: "待观看"
```

### 案例四：知识库自动构建

知识工作者小刘希望将阅读的内容自动整理成知识库：

```yaml
name: knowledge-base-builder

triggers:
  - type: schedule
    cron: "0 22 * * *"  # 每天晚上10点

steps:
  - name: get_today_articles
    skill: database
    command: query
    args:
      sql: |
        SELECT * FROM articles
        WHERE date(created_at) = date('now')
        AND status = 'read'

  - name: extract_knowledge
    agent: knowledge-extractor
    prompt: |
      从以下文章中提取知识点：
      {{steps.get_today_articles.output}}

      对每个知识点，请提供：
      - 概念名称
      - 定义/解释
      - 相关文章链接
      - 建议的分类标签

  - name: update_obsidian
    skill: obsidian
    command: create-notes
    args:
      vault_path: "{{user.obsidian_vault}}"
      notes: "{{steps.extract_knowledge.output}}"

  - name: build_graph
    skill: obsidian
    command: update-graph
    args:
      create_links: true
      link_threshold: 0.8
```

## 进阶技巧

### 语义搜索与问答

```yaml
- name: semantic_search
  skill: vector-db
  command: search
  args:
    query_embedding: "{{input.query | embed}}"
    collection: "articles"
    top_k: 5

- name: answer_question
  agent: research-assistant
  prompt: |
    基于以下相关资料，回答用户问题：
    问题：{{input.question}}
    相关资料：{{steps.semantic_search.output}}

    请提供准确、简洁的回答，并标注信息来源。
```

### 阅读进度追踪

```yaml
- name: track_reading
  skill: database
  command: update
  args:
    table: "articles"
    set:
      status: "{{input.status}}"  # unread/reading/read
      read_time: "{{input.time_spent}}"
      rating: "{{input.user_rating}}"
    where:
      url: "{{input.article_url}}"

- name: generate_stats
  agent: data-analyst
  prompt: |
    基于用户阅读数据，生成月度阅读报告：
    {{user.reading_history}}

    请分析：
    1. 阅读数量趋势
    2. 偏好的内容类型
    3. 平均阅读时长
    4. 阅读效率建议
```

通过这些配置，OpenClaw 可以帮助你构建一个强大的个人知识管理系统，让内容消费从负担变成享受，让知识积累从被动变成主动。
